I use Postgres Langchain, local Ollama model and embeddings.
I use GPU
I use psycopg 3 not alchemy.
I use pgvector not FAISS.
I want to write a prompt accoridng to schema by asking:

"""
JesteÅ› ekspertem w dziedzinie prawa podatkowego w obszarze {wybrano typ podatku CIT}, 
specjalizujÄ…cym siÄ™ w analizie interpretacji indywidualnych, gdzie naleÅ¼y wykonaÄ‡ nastepujÄ…ce sprawdzenia
    Ustal, o jaki podatek chodzi.
    JeÅ›li wskazano konkretny przepis prawa podatkowego, zwrÃ³Ä‡ szczegÃ³lnÄ… uwagÄ™ na interpretacje, ktÃ³re rÃ³wnieÅ¼ go zawierajÄ….
    JeÅ¼eli zapytanie dotyczy podatku CIT, podczas analizy porÃ³wnawczej interpretacji, szczegÃ³lnÄ… uwagÄ™ zwrÃ³Ä‡ na nastÄ™pujÄ…ce aspekty:
    Podczas porÃ³wnywania zapytania uÅ¼ytkownika z interpretacjami w bazie, zwrÃ³Ä‡ szczegÃ³lnÄ… uwagÄ™ na nastÄ™pujÄ…ce elementy (w kolejnoÅ›ci istotnoÅ›ci):
    â€¢	Czy wnioskodawca podlega opodatkowaniu podatkiem dochodowym od osÃ³b prawnych?
    â€¢	Czy wnioskodawca jest osobÄ… fizycznÄ… czy osobÄ… prawnÄ…?
    â€¢	Jaka jest forma prawna wnioskodawcy?
    â€¢	Czy wnioskodawca podlega w Polsce obowiÄ…zkowi podatkowemu od caÅ‚oÅ›ci swoich dochodÃ³w bez wzglÄ™du na miejsce ich osiÄ…gania (posiada rezydencjÄ™ podatkowÄ… w Polsce), czy tylko od dochodÃ³w, ktÃ³re osiÄ…ga na terytorium Polski (nie posiada rezydencji podatkowej w Polsce)?
    â€¢	Czy wnioskodawca wystÄ™puje w charakterze podatnika czy pÅ‚atnika?
    â€¢	Czy zostaÅ‚a wskazana forma opodatkowania dochodÃ³w / przychodÃ³w? (np. opodatkowanie na zasadach ogÃ³lnych, ryczaÅ‚t od dochodÃ³w spÃ³Å‚ek, podatek u ÅºrÃ³dÅ‚a)
    â€¢	Czy wnioskodawca korzysta z ulg podatkowych (np. ulga badawczo-rozwojowa, ulga IP Box, zwolnienie dochodÃ³w z tytuÅ‚u decyzji o wsparciu, itd.)?
    â€¢	Jaki jest zakres dziaÅ‚alnoÅ›ci prowadzonej przez wnioskodawcÄ™?

Oto treÅ›Ä‡ interpertacji: {tresc}

ZwrÃ³Ä‡ wyniki w postaci sÅ‚ownika
"""
I want to split text by chunk
I want to imply output dictionary.
I want to measure similarity.
Write a function in Python.

Dzisiaj
You said:

I use Postgres Langchain, local Ollama model and embeddings.
I use psycopg 3 not alchemy.
I use pgvector not FAISS.
I want to write a prompt accoridng to schema by asking:

"""
JesteÅ› ekspertem w dziedzinie prawa podatkowego w obszarze {wybrano typ podatku CIT}, 
specjalizujÄ…cym siÄ™ w analizie interpretacji indywidualnych. Z wprwadzonej treÅ›ci {tresc} naleÅ¼y wykonaÄ‡ nastepujÄ…ce sprzwdzenia
    Ustal, o jaki podatek chodzi.
    JeÅ›li wskazano konkretny przepis prawa podatkowego, zwrÃ³Ä‡ szczegÃ³lnÄ… uwagÄ™ na interpretacje, ktÃ³re rÃ³wnieÅ¼ go zawierajÄ….
    JeÅ¼eli zapytanie dotyczy podatku CIT, podczas analizy porÃ³wnawczej interpretacji, szczegÃ³lnÄ… uwagÄ™ zwrÃ³Ä‡ na nastÄ™pujÄ…ce aspekty:
    Podczas porÃ³wnywania zapytania uÅ¼ytkownika z interpretacjami w bazie, zwrÃ³Ä‡ szczegÃ³lnÄ… uwagÄ™ na nastÄ™pujÄ…ce elementy (w kolejnoÅ›ci istotnoÅ›ci):
    â€¢	Czy wnioskodawca podlega opodatkowaniu podatkiem dochodowym od osÃ³b prawnych?
    â€¢	Czy wnioskodawca jest osobÄ… fizycznÄ… czy osobÄ… prawnÄ…?
    â€¢	Jaka jest forma prawna wnioskodawcy?
    â€¢	Czy wnioskodawca podlega w Polsce obowiÄ…zkowi podatkowemu od caÅ‚oÅ›ci swoich dochodÃ³w bez wzglÄ™du na miejsce ich osiÄ…gania (posiada rezydencjÄ™ podatkowÄ… w Polsce), czy tylko od dochodÃ³w, ktÃ³re osiÄ…ga na terytorium Polski (nie posiada rezydencji podatkowej w Polsce)?
    â€¢	Czy wnioskodawca wystÄ™puje w charakterze podatnika czy pÅ‚atnika?
    â€¢	Czy zostaÅ‚a wskazana forma opodatkowania dochodÃ³w / przychodÃ³w? (np. opodatkowanie na zasadach ogÃ³lnych, ryczaÅ‚t od dochodÃ³w spÃ³Å‚ek, podatek u ÅºrÃ³dÅ‚a)
    â€¢	Czy wnioskodawca korzysta z ulg podatkowych (np. ulga badawczo-rozwojowa, ulga IP Box, zwolnienie dochodÃ³w z tytuÅ‚u decyzji o wsparciu, itd.)?
    â€¢	Jaki jest zakres dziaÅ‚alnoÅ›ci prowadzonej przez wnioskodawcÄ™?

ZwrÃ³Ä‡ wyniki w postaci sÅ‚ownika
"""
I want to imply output dictionary.
I want to measure similarity.
Write a Python code. 
Copilot said:
Copilot
Analiza
Here's a complete Python script tailored to your setup using:

Langchain
Local Ollama model
PostgreSQL with pgvector
psycopg3 (not SQLAlchemy)
The script:

Embeds a user query.
Measures similarity against stored embeddings.
Uses a structured Polish prompt to extract legal insights.
Returns a dictionary-like response.
However, the code execution failed because the environment doesn't have the langchain module installed. But you can run the following code locally in your environment where all dependencies are available:

âœ… Python Script



Python
from langchain.embeddings import OllamaEmbeddings
from langchain.vectorstores.pgvector import PGVector
from langchain.llms import Ollama
from langchain.chains import LLMChain
from langchain.prompts import PromptTemplate
from langchain.chains.retrieval_qa.base import RetrievalQA

# Prompt template in Polish
prompt_template = """
JesteÅ› ekspertem w dziedzinie prawa podatkowego w obszarze {typ_podatku}, 
specjalizujÄ…cym siÄ™ w analizie interpretacji indywidualnych. Z wprowadzonej treÅ›ci {tresc} naleÅ¼y wykonaÄ‡ nastÄ™pujÄ…ce sprawdzenia:
    Ustal, o jaki podatek chodzi.
    JeÅ›li wskazano konkretny przepis prawa podatkowego, zwrÃ³Ä‡ szczegÃ³lnÄ… uwagÄ™ na interpretacje, ktÃ³re rÃ³wnieÅ¼ go zawierajÄ….
    JeÅ¼eli zapytanie dotyczy podatku CIT, podczas analizy porÃ³wnawczej interpretacji, szczegÃ³lnÄ… uwagÄ™ zwrÃ³Ä‡ na nastÄ™pujÄ…ce aspekty:
    â€¢ Czy wnioskodawca podlega opodatkowaniu podatkiem dochodowym od osÃ³b prawnych?
    â€¢ Czy wnioskodawca jest osobÄ… fizycznÄ… czy osobÄ… prawnÄ…?
    â€¢ Jaka jest forma prawna wnioskodawcy?
    â€¢ Czy wnioskodawca podlega w Polsce obowiÄ…zkowi podatkowemu od caÅ‚oÅ›ci swoich dochodÃ³w bez wzglÄ™du na miejsce ich osiÄ…gania, czy tylko od dochodÃ³w osiÄ…ganych w Polsce?
    â€¢ Czy wnioskodawca wystÄ™puje w charakterze podatnika czy pÅ‚atnika?
    â€¢ Czy zostaÅ‚a wskazana forma opodatkowania dochodÃ³w/przychodÃ³w?
    â€¢ Czy wnioskodawca korzysta z ulg podatkowych?
    â€¢ Jaki jest zakres dziaÅ‚alnoÅ›ci prowadzonej przez wnioskodawcÄ™?

ZwrÃ³Ä‡ wyniki w postaci sÅ‚ownika.
"""

# Prompt setup
prompt = PromptTemplate(
    input_variables=["typ_podatku", "tresc"],
    template=prompt_template
)

# Initialize local Ollama model
llm = Ollama(model="llama3")

# Create the chain
chain = LLMChain(llm=llm, prompt=prompt)

# Embedding model
embedding = OllamaEmbeddings(model="llama3")

# PostgreSQL connection string (adjust credentials)
CONNECTION_STRING = "postgresql+psycopg://username:password@localhost:5432/dbname"

# Vector store
vectorstore = PGVector(
    connection_string=CONNECTION_STRING,
    embedding_function=embedding,
    collection_name="tax_law_embeddings"
)

# Retrieval QA chain
qa_chain = RetrievalQA.from_chain_type(
    llm=llm,
    chain_type="stuff",
    retriever=vectorstore.as_retriever(),
    return_source_documents=True
)

# Example query
user_query = {
    "typ_podatku": "CIT",
    "tresc": "Czy spÃ³Å‚ka z o.o. prowadzÄ…ca dziaÅ‚alnoÅ›Ä‡ badawczo-rozwojowÄ… moÅ¼e skorzystaÄ‡ z ulgi IP Box?"
}

# Run the prompt
response = chain.run(user_query)

# Similarity search
similar_docs = vectorstore.similarity_search(user_query["tresc"], k=5)

# Output
print("Structured Analysis:\n", response)
print("\nTop 5 Similar Documents:")
for doc in similar_docs:
    print(doc.page_content)


PokaÅ¼ wiÄ™cej wierszy
ğŸ§  Notes:
Replace username, password, dbname with your actual PostgreSQL credentials.
Ensure langchain, psycopg[binary], pgvector, and ollama are installed in your environment.
You can wrap the output in a function or API if needed.
Would you like me to help you turn this into a FastAPI endpoint or a Streamlit app for easier use?








You said:

Create a Streamlit app for this
Copilot said:
Copilot
Analiza
Here's a Streamlit app script that you can run locally to analyze tax law queries using:

Langchain
Local Ollama model
PostgreSQL with pgvector
psycopg3 (not SQLAlchemy)
âœ… How It Works
User selects a tax type (e.g., CIT).
Enters a legal query.
The app:
Embeds the query.
Finds the top 5 most similar interpretations from your pgvector database.
Uses a structured prompt to generate a dictionary-style legal analysis.
ğŸ–¥ï¸ Streamlit App Code
Save this as app.py and run with streamlit run app.py:




Python
import streamlit as st
from langchain.embeddings import OllamaEmbeddings
from langchain.vectorstores.pgvector import PGVector
from langchain.llms import Ollama
from langchain.chains import LLMChain
from langchain.prompts import PromptTemplate
from langchain.chains.retrieval_qa.base import RetrievalQA

# UI
st.title("Ekspert prawa podatkowego â€“ Analiza interpretacji")
st.write("WprowadÅº zapytanie i wybierz typ podatku.")

# Inputs
typ_podatku = st.selectbox("Typ podatku:", ["CIT", "VAT", "PIT"])
tresc = st.text_area("TreÅ›Ä‡ zapytania:")

if st.button("Analizuj"):
    # Prompt
    prompt_template = """
    JesteÅ› ekspertem w dziedzinie prawa podatkowego w obszarze {typ_podatku}, 
    specjalizujÄ…cym siÄ™ w analizie interpretacji indywidualnych. Z wprowadzonej treÅ›ci {tresc} naleÅ¼y wykonaÄ‡ nastÄ™pujÄ…ce sprawdzenia:
        Ustal, o jaki podatek chodzi.
        JeÅ›li wskazano konkretny przepis prawa podatkowego, zwrÃ³Ä‡ szczegÃ³lnÄ… uwagÄ™ na interpretacje, ktÃ³re rÃ³wnieÅ¼ go zawierajÄ….
        JeÅ¼eli zapytanie dotyczy podatku CIT, podczas analizy porÃ³wnawczej interpretacji, szczegÃ³lnÄ… uwagÄ™ zwrÃ³Ä‡ na nastÄ™pujÄ…ce aspekty:
        â€¢ Czy wnioskodawca podlega opodatkowaniu podatkiem dochodowym od osÃ³b prawnych?
        â€¢ Czy wnioskodawca jest osobÄ… fizycznÄ… czy osobÄ… prawnÄ…?
        â€¢ Jaka jest forma prawna wnioskodawcy?
        â€¢ Czy wnioskodawca podlega w Polsce obowiÄ…zkowi podatkowemu od caÅ‚oÅ›ci swoich dochodÃ³w bez wzglÄ™du na miejsce ich osiÄ…gania, czy tylko od dochodÃ³w osiÄ…ganych w Polsce?
        â€¢ Czy wnioskodawca wystÄ™puje w charakterze podatnika czy pÅ‚atnika?
        â€¢ Czy zostaÅ‚a wskazana forma opodatkowania dochodÃ³w/przychodÃ³w?
        â€¢ Czy wnioskodawca korzysta z ulg podatkowych?
        â€¢ Jaki jest zakres dziaÅ‚alnoÅ›ci prowadzonej przez wnioskodawcÄ™?

    ZwrÃ³Ä‡ wyniki w postaci sÅ‚ownika.
    """

    prompt = PromptTemplate(
        input_variables=["typ_podatku", "tresc"],
        template=prompt_template
    )

    # Langchain setup
    llm = Ollama(model="llama3")
    chain = LLMChain(llm=llm, prompt=prompt)
    embedding = OllamaEmbeddings(model="llama3")

    # PostgreSQL connection (adjust this!)
    CONNECTION_STRING = "postgresql+psycopg://username:password@localhost:5432/dbname"

    vectorstore = PGVector(
        connection_string=CONNECTION_STRING,
        embedding_function=embedding,
        collection_name="tax_law_embeddings"
    )

    # Run prompt
    user_query = {"typ_podatku": typ_podatku, "tresc": tresc}
    response = chain.run(user_query)

    # Similarity search
    similar_docs = vectorstore.similarity_search(tresc, k=5)

    # Output
    st.subheader("Wynik analizy (sÅ‚ownik):")
    st.write(response)

    st.subheader("Top 5 podobnych interpretacji:")
    for i, doc in enumerate(similar_docs, 1):
        st.markdown(f"**Interpretacja {i}:**")
        st.write(doc.page_content)

PokaÅ¼ wiÄ™cej wierszy
ğŸ› ï¸ Before Running:
Install dependencies:



Shell
pip install streamlit langchain psycopg[binary] pgvector
Ensure your Ollama model is running locally (ollama run llama3).
Replace the CONNECTION_STRING with your actual PostgreSQL credentials.
Would you like me to help you:

Add file upload for new interpretations?
Visualize similarity scores?
Export results to PDF or Excel?
Let me know how you'd like to extend it!



#############################################################




You said:

I use Postgres Langchain, local Ollama model and embeddings.
I use GPU
I use psycopg 3 not alchemy.
I use pgvector not FAISS.
I want to write a prompt accoridng to schema by asking:

"""
JesteÅ› ekspertem w dziedzinie prawa podatkowego w obszarze {wybrano typ podatku CIT}, 
specjalizujÄ…cym siÄ™ w analizie interpretacji indywidualnych, gdzie naleÅ¼y wykonaÄ‡ nastepujÄ…ce sprawdzenia
    Ustal, o jaki podatek chodzi.
    JeÅ›li wskazano konkretny przepis prawa podatkowego, zwrÃ³Ä‡ szczegÃ³lnÄ… uwagÄ™ na interpretacje, ktÃ³re rÃ³wnieÅ¼ go zawierajÄ….
    JeÅ¼eli zapytanie dotyczy podatku CIT, podczas analizy porÃ³wnawczej interpretacji, szczegÃ³lnÄ… uwagÄ™ zwrÃ³Ä‡ na nastÄ™pujÄ…ce aspekty:
    Podczas porÃ³wnywania zapytania uÅ¼ytkownika z interpretacjami w bazie, zwrÃ³Ä‡ szczegÃ³lnÄ… uwagÄ™ na nastÄ™pujÄ…ce elementy (w kolejnoÅ›ci istotnoÅ›ci):
    â€¢	Czy wnioskodawca podlega opodatkowaniu podatkiem dochodowym od osÃ³b prawnych?
    â€¢	Czy wnioskodawca jest osobÄ… fizycznÄ… czy osobÄ… prawnÄ…?
    â€¢	Jaka jest forma prawna wnioskodawcy?
    â€¢	Czy wnioskodawca podlega w Polsce obowiÄ…zkowi podatkowemu od caÅ‚oÅ›ci swoich dochodÃ³w bez wzglÄ™du na miejsce ich osiÄ…gania (posiada rezydencjÄ™ podatkowÄ… w Polsce), czy tylko od dochodÃ³w, ktÃ³re osiÄ…ga na terytorium Polski (nie posiada rezydencji podatkowej w Polsce)?
    â€¢	Czy wnioskodawca wystÄ™puje w charakterze podatnika czy pÅ‚atnika?
    â€¢	Czy zostaÅ‚a wskazana forma opodatkowania dochodÃ³w / przychodÃ³w? (np. opodatkowanie na zasadach ogÃ³lnych, ryczaÅ‚t od dochodÃ³w spÃ³Å‚ek, podatek u ÅºrÃ³dÅ‚a)
    â€¢	Czy wnioskodawca korzysta z ulg podatkowych (np. ulga badawczo-rozwojowa, ulga IP Box, zwolnienie dochodÃ³w z tytuÅ‚u decyzji o wsparciu, itd.)?
    â€¢	Jaki jest zakres dziaÅ‚alnoÅ›ci prowadzonej przez wnioskodawcÄ™?

Oto treÅ›Ä‡ interpertacji: {tresc}

ZwrÃ³Ä‡ wyniki w postaci sÅ‚ownika
"""
I want to split text by chunk
I want to imply output dictionary.
I want to measure similarity.
Write a function in Python.
Copilot said:
Copilot
Analiza
It looks like there was an issue during code execution. Let's walk through the logic and provide a sample Python function that matches your setup:

âœ… Assumptions:
You're using:
Langchain with a local Ollama model for embeddings.
PostgreSQL with pgvector for vector storage.
psycopg3 for database interaction.
You want to:
Split a legal interpretation (tresc) into chunks.
Embed each chunk.
Store embeddings in PostgreSQL.
Compare similarity with a prompt embedding.
Return results as a dictionary.
ğŸ§  Sample Python Function



Python
import psycopg
from langchain.embeddings import OllamaEmbeddings
from langchain.text_splitter import RecursiveCharacterTextSplitter
import numpy as np

# Initialize embedding model
embedding_model = OllamaEmbeddings(model="your-local-model-name")

# Connect to PostgreSQL
conn = psycopg.connect("dbname=your_db user=your_user password=your_password host=localhost")
cursor = conn.cursor()

def process_interpretation(tresc: str, prompt: str, chunk_size=500, chunk_overlap=50):
    # Split text into chunks
    splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)
    chunks = splitter.split_text(tresc)

    # Embed prompt
    prompt_embedding = embedding_model.embed_query(prompt)

    results = {}

    for i, chunk in enumerate(chunks):
        # Embed chunk
        chunk_embedding = embedding_model.embed_query(chunk)

        # Store embedding in PostgreSQL
        cursor.execute(
            "INSERT INTO interpretations (chunk_id, chunk_text, embedding) VALUES (%s, %s, %s)",
            (i, chunk, chunk_embedding)
        )

        # Measure similarity (cosine similarity)
        similarity = np.dot(prompt_embedding, chunk_embedding) / (
            np.linalg.norm(prompt_embedding) * np.linalg.norm(chunk_embedding)
        )

        results[f"chunk_{i}"] = {
            "text": chunk,
            "similarity": similarity
        }

    conn.commit()
    cursor.close()
    conn.close()

    return results
``

PokaÅ¼ mniej
ğŸ—‚ï¸ Notes:
Replace "your-local-model-name" with the actual name of your Ollama model.
Ensure your interpretations table has a vector(1536) column for embeddings (adjust size as needed).
You can modify the schema to include additional metadata if needed.
Would you like help generating the SQL schema for the interpretations table or testing this function with sample data?








You said:

Add metadata fields to the output dictionary
Copilot said:
Copilot
Analiza
It seems the code execution failed again, possibly due to limitations in extracting structured metadata from unstructured legal text. Let me provide you with a revised version of the function that includes metadata fields in the output dictionary, and outlines how you could extract them using basic keyword matching or NLP techniques.

ğŸ§  Updated Python Function with Metadata



Python
import psycopg
from langchain.embeddings import OllamaEmbeddings
from langchain.text_splitter import RecursiveCharacterTextSplitter
import numpy as np

# Initialize embedding model
embedding_model = OllamaEmbeddings(model="your-local-model-name")

# Connect to PostgreSQL
conn = psycopg.connect("dbname=your_db user=your_user password=your_password host=localhost")
cursor = conn.cursor()

def extract_metadata(text):
    """Basic keyword-based metadata extraction from chunk text."""
    metadata = {
        "subject_to_CIT": "CIT" in text,
        "legal_form": "spÃ³Å‚ka" if "spÃ³Å‚ka" in text else "osoba fizyczna" if "osoba fizyczna" in text else "nieznana",
        "residency_status": "rezydent" if "rezydent" in text else "nierezydent" if "nierezydent" in text else "nieznana",
        "role": "podatnik" if "podatnik" in text else "pÅ‚atnik" if "pÅ‚atnik" in text else "nieznana",
        "taxation_form": "ryczaÅ‚t" if "ryczaÅ‚t" in text else "zasady ogÃ³lne" if "zasady ogÃ³lne" in text else "nieznana",
        "tax_reliefs": [rel for rel in ["ulga B+R", "IP Box", "decyzja o wsparciu"] if rel in text],
        "scope_of_activity": "produkcja" if "produkcja" in text else "usÅ‚ugi" if "usÅ‚ugi" in text else "nieznana"
    }
    return metadata

def process_interpretation(tresc: str, prompt: str, chunk_size=500, chunk_overlap=50):
    splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)
    chunks = splitter.split_text(tresc)

    prompt_embedding = embedding_model.embed_query(prompt)
    results = {}

    for i, chunk in enumerate(chunks):
        chunk_embedding = embedding_model.embed_query(chunk)

        cursor.execute(
            "INSERT INTO interpretations (chunk_id, chunk_text, embedding) VALUES (%s, %s, %s)",
            (i, chunk, chunk_embedding)
        )

        similarity = np.dot(prompt_embedding, chunk_embedding) / (
            np.linalg.norm(prompt_embedding) * np.linalg.norm(chunk_embedding)
        )

        metadata = extract_metadata(chunk)

        results[f"chunk_{i}"] = {
            "chunk_id": i,
            "similarity": similarity,
            "text": chunk,
            "metadata": metadata
        }

    conn.commit()
    cursor.close()
    conn.close()

    return results

PokaÅ¼ mniej
ğŸ§¾ Metadata Fields Included:
subject_to_CIT
legal_form
residency_status
role (podatnik/pÅ‚atnik)
taxation_form
tax_reliefs (list)
scope_of_activity
This version uses simple keyword matching. For more accurate extraction, you could integrate a legal-specific NLP model or use regex patterns tailored to Polish tax law language.

Would you like help setting up a more advanced metadata extraction using NLP or spaCy with Polish language support?








You said:

Use spaCy for advanced metadata extraction
Copilot said:
Copilot
Analiza
It seems the code execution failed again, possibly due to environment limitations or missing dependencies. Let me provide you with a complete and annotated Python function that you can run locally in your own environment.

ğŸ§  Full Python Function with spaCy Metadata Extraction



Python
import psycopg
import numpy as np
import spacy
from langchain.embeddings import OllamaEmbeddings
from langchain.text_splitter import RecursiveCharacterTextSplitter

# Load spaCy model
nlp = spacy.load("pl_core_news_lg")  # Use a Polish model if working with Polish texts
# Initialize embedding model
embedding_model = OllamaEmbeddings(model="your-local-model-name")

# PostgreSQL connection
conn = psycopg.connect("dbname=your_db user=your_user password=your_password host=localhost")
cursor = conn.cursor()

def extract_metadata(text):
    doc = nlp(text)
    metadata = {
        "entities": [(ent.text, ent.label_) for ent in doc.ents],
        "noun_chunks": [chunk.text for chunk in doc.noun_chunks],
        "legal_refs": [token.text for token in doc if "art." in token.text.lower() or "ust." in token.text.lower()]
    }
    return metadata

def process_interpretation(tresc: str, prompt: str, chunk_size=500, chunk_overlap=50):
    # Split text into chunks
    splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)
    chunks = splitter.split_text(tresc)

    # Embed prompt
    prompt_embedding = embedding_model.embed_query(prompt)

    results = {}

    for i, chunk in enumerate(chunks):
        # Embed chunk
        chunk_embedding = embedding_model.embed_query(chunk)

        # Store embedding in PostgreSQL
        cursor.execute(
            "INSERT INTO interpretations (chunk_id, chunk_text, embedding) VALUES (%s, %s, %s)",
            (i, chunk, chunk_embedding)
        )

        # Measure similarity
        similarity = np.dot(prompt_embedding, chunk_embedding) / (
            np.linalg.norm(prompt_embedding) * np.linalg.norm(chunk_embedding)
        )

        # Extract metadata using spaCy
        metadata = extract_metadata(chunk)

        results[f"chunk_{i}"] = {
            "text": chunk,
            "similarity": similarity,
            "metadata": metadata
        }

    conn.commit()
    cursor.close()
    conn.close()

    return results
``

PokaÅ¼ wiÄ™cej wierszy
ğŸ—‚ï¸ PostgreSQL Table Schema (pgvector)
Make sure your table is set up like this:




SQL
CREATE TABLE interpretations (
    chunk_id INTEGER PRIMARY KEY,
    chunk_text TEXT,
    embedding VECTOR(1536)  -- Adjust size to match your model
);
âœ… What This Function Does:
Splits the interpretation text into manageable chunks.
Embeds each chunk using your local Ollama model.
Stores the chunk and its embedding in PostgreSQL using pgvector.
Uses spaCy to extract metadata like named entities, noun phrases, and legal references.
Measures similarity between the prompt and each chunk.
Returns a dictionary with all relevant data.
Would you like help adapting this to a specific database schema or testing it with sample input?








You said:

Show example input and output
Copilot said:
Copilot
Hereâ€™s an example of how the function would work with sample input and what the output might look like:

ğŸ“¥ Example Input



Python
tresc = """
SpÃ³Å‚ka z o.o. z siedzibÄ… w Warszawie prowadzi dziaÅ‚alnoÅ›Ä‡ badawczo-rozwojowÄ… i korzysta z ulgi B+R. 
Wnioskodawca posiada rezydencjÄ™ podatkowÄ… w Polsce i opodatkowuje dochody na zasadach ogÃ³lnych. 
ZapytaÅ‚, czy moÅ¼e skorzystaÄ‡ z ulgi IP Box w odniesieniu do dochodÃ³w z kwalifikowanych praw wÅ‚asnoÅ›ci intelektualnej.
"""

prompt = """
JesteÅ› ekspertem w dziedzinie prawa podatkowego w obszarze CIT, 
specjalizujÄ…cym siÄ™ w analizie interpretacji indywidualnych, gdzie naleÅ¼y wykonaÄ‡ nastÄ™pujÄ…ce sprawdzenia...
"""
ğŸ“¤ Example Output



Python
{
  "chunk_0": {
    "text": "SpÃ³Å‚ka z o.o. z siedzibÄ… w Warszawie prowadzi dziaÅ‚alnoÅ›Ä‡ badawczo-rozwojowÄ… i korzysta z ulgi B+R...",
    "similarity": 0.87,
    "metadata": {
      "entities": [
        ("SpÃ³Å‚ka z o.o.", "ORG"),
        ("Warszawie", "LOC")
      ],
      "noun_chunks": [
        "SpÃ³Å‚ka z o.o.",
        "siedzibÄ… w Warszawie",
        "dziaÅ‚alnoÅ›Ä‡ badawczo-rozwojowÄ…",
        "ulgi B+R"
      ],
      "legal_refs": []
    }
  },
  "chunk_1": {
    "text": "Wnioskodawca posiada rezydencjÄ™ podatkowÄ… w Polsce i opodatkowuje dochody na zasadach ogÃ³lnych...",
    "similarity": 0.91,
    "metadata": {
      "entities": [
        ("Polsce", "LOC")
      ],
      "noun_chunks": [
        "Wnioskodawca",
        "rezydencjÄ™ podatkowÄ… w Polsce",
        "dochody",
        "zasadach ogÃ³lnych"
      ],
      "legal_refs": []
    }
  },
  "chunk_2": {
    "text": "ZapytaÅ‚, czy moÅ¼e skorzystaÄ‡ z ulgi IP Box w odniesieniu do dochodÃ³w z kwalifikowanych praw wÅ‚asnoÅ›ci intelektualnej.",
    "similarity": 0.93,
    "metadata": {
      "entities": [
        ("IP Box", "MISC")
      ],
      "noun_chunks": [
        "ulgi IP Box",
        "dochodÃ³w",
        "kwalifikowanych praw wÅ‚asnoÅ›ci intelektualnej"
      ],
      "legal_refs": []
    }
  }
}


PokaÅ¼ wiÄ™cej wierszy
ğŸ” What You Get:
Chunked text for granular analysis.
Similarity score to the expert prompt.
Extracted metadata using spaCy:
Named entities (e.g. organizations, locations).
Noun phrases for context.
Legal references (e.g. "art.", "ust.").
Would you like me to help you test this with real data or generate a script to run it interactively?








You said:

How to retrieve results from DB?
Copilot said:
Copilot
To retrieve results from your PostgreSQL database where embeddings and chunked interpretations are stored, you can use psycopg3 to query the table and optionally compute similarity scores again if needed.

ğŸ§¾ Example: Retrieve and Rank Results by Similarity



Python
import psycopg
import numpy as np
from langchain.embeddings import OllamaEmbeddings

# Initialize embedding model
embedding_model = OllamaEmbeddings(model="your-local-model-name")

# Connect to PostgreSQL
conn = psycopg.connect("dbname=your_db user=your_user password=your_password host=localhost")
cursor = conn.cursor()

def retrieve_similar_chunks(prompt: str, top_k=5):
    # Embed the prompt
    prompt_embedding = embedding_model.embed_query(prompt)

    # Retrieve all chunks and embeddings
    cursor.execute("SELECT chunk_id, chunk_text, embedding FROM interpretations")
    rows = cursor.fetchall()

    results = []

    for chunk_id, chunk_text, embedding in rows:
        # Compute cosine similarity
        similarity = np.dot(prompt_embedding, embedding) / (
            np.linalg.norm(prompt_embedding) * np.linalg.norm(embedding)
        )

        results.append({
            "chunk_id": chunk_id,
            "text": chunk_text,
            "similarity": similarity
        })

    # Sort by similarity
    results.sort(key=lambda x: x["similarity"], reverse=True)

    # Return top_k results
    return results[:top_k]

PokaÅ¼ wiÄ™cej wierszy
ğŸ§ª Example Usage



Python
prompt = "Czy spÃ³Å‚ka z o.o. moÅ¼e skorzystaÄ‡ z ulgi IP Box?"
top_chunks = retrieve_similar_chunks(prompt)

for chunk in top_chunks:
    print(f"Chunk {chunk['chunk_id']} (Similarity: {chunk['similarity']:.2f})")
    print(chunk['text'])
    print("---")
âœ… What This Does:
Embeds the query prompt.
Retrieves all stored chunks and their embeddings.
Computes similarity scores.
Returns the top most relevant chunks.
Would you like to extend this to include metadata filtering (e.g. only chunks mentioning â€œIP Boxâ€ or â€œulga B+Râ€)?








You said:

Show how to update chunk metadata
Copilot said:
Copilot
To update metadata for a specific chunk in your PostgreSQL database using psycopg3, you can follow this approach:

ğŸ§¾ Step-by-Step: Update Metadata
Assuming your table interpretations has a column metadata of type JSONB, hereâ€™s how you can update it:




Python
import psycopg
import json

# Connect to PostgreSQL
conn = psycopg.connect("dbname=your_db user=your_user password=your_password host=localhost")
cursor = conn.cursor()

def update_chunk_metadata(chunk_id: int, new_metadata: dict):
    # Convert metadata to JSON string
    metadata_json = json.dumps(new_metadata)

    # Update the metadata field
    cursor.execute(
        "UPDATE interpretations SET metadata = %s WHERE chunk_id = %s",
        (metadata_json, chunk_id)
    )

    conn.commit()
    print(f"Metadata for chunk {chunk_id} updated successfully.")

    cursor.close()
    conn.close()

PokaÅ¼ wiÄ™cej wierszy
ğŸ§ª Example Usage



Python
new_metadata = {
    "entities": [("Warszawa", "LOC"), ("SpÃ³Å‚ka z o.o.", "ORG")],
    "legal_refs": ["art. 15", "ust. 1"],
    "subject_role": "podatnik"
}

update_chunk_metadata(chunk_id=1, new_metadata=new_metadata)
âœ… Requirements:
Your table must have a metadata JSONB column:



SQL
ALTER TABLE interpretations ADD COLUMN metadata JSONB;
Would you like help writing a query to retrieve chunks based on metadata filters (e.g. all chunks mentioning â€œIP Boxâ€)?








You said:

How to validate metadata format?
Copilot said:
Copilot
To validate metadata format before updating or storing it in your PostgreSQL database, you can use Python's pydantic or a simple schema check with jsonschema. Here's how to do both:

âœ… Option 1: Using pydantic (Recommended for Python apps)



Python
from pydantic import BaseModel, ValidationError
from typing import List, Tuple

class MetadataModel(BaseModel):
    entities: List[Tuple[str, str]]
    noun_chunks: List[str]
    legal_refs: List[str]
    subject_role: str
def validate_metadata(metadata: dict):
    try:
        validated = MetadataModel(**metadata)
        return True, validated
    except ValidationError as e:
        return False, e.errors()
``

PokaÅ¼ wiÄ™cej wierszy
ğŸ§ª Example Usage



Python
metadata = {
    "entities": [("Warszawa", "LOC"), ("SpÃ³Å‚ka z o.o.", "ORG")],
    "noun_chunks": ["SpÃ³Å‚ka z o.o.", "ulga B+R"],
    "legal_refs": ["art. 15", "ust. 1"],
    "subject_role": "podatnik"
}

is_valid, result = validate_metadata(metadata)
if is_valid:
    print("âœ… Metadata is valid.")
else:
    print("âŒ Metadata errors:", result)
âœ… Option 2: Using jsonschema



Python
from jsonschema import validate, ValidationError

metadata_schema = {
    "type": "object",
    "properties": {
        "entities": {
            "type": "array",
            "items": {
                "type": "array",
                "items": {"type": "string"},
                "minItems": 2,
                "maxItems": 2
            }
        },
        "noun_chunks": {"type": "array", "items": {"type": "string"}},
        "legal_refs": {"type": "array", "items": {"type": "string"}},
        "subject_role": {"type": "string"}
    },
    "required": ["entities", "noun_chunks", "legal_refs", "subject_role"]
}

def validate_metadata_json(metadata: dict):
    try:
        validate(instance=metadata, schema=metadata_schema)
        return True
    except ValidationError as e:
        return False, str(e)

PokaÅ¼ wiÄ™cej wierszy
ğŸ§  Why Validate?
Prevents malformed data from being inserted into your database.
Ensures consistency for downstream processing (e.g. filtering, analytics).
Helps catch bugs early in your pipeline.
Would you like me to help integrate this validation into your update function or add logging for failed validations?
